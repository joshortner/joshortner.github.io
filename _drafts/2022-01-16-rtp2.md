---
layout: post
title: Ray Tracing Journey - Pt2
type: blog
permalink: raytracing-part-two
usemathjax: true

aliasingpost: "[[2]](#aliasing-in-computer-graphics)"
---

* TOC
{:toc}

# 1. Introduction

I'll keep this intro short and sweet. This post picks up where the [first](https://joshortner.github.io/raytracing-part-one) raytracing post left off. I'll be starting at section 7, Antialiasing, in [RTIOW](https://raytracing.github.io/books/RayTracingInOneWeekend.html#antialiasing).

# 2. Aliasing 

## 2.1 Tangent Warning

I was first introduced to the concept of aliasing pretty early on in my graphics jouney. The moment you want to draw something that isn't a perfectly vertical or horizontal line, you'll notice an artifact coloquially referred to as "jaggies."

When I'm learning something new that is complex, it's easy for me to loose sight of the fundamentals, the first-principles underlying the idea. This was definitely the case when I first started learning computer graphics. It's such a large beast, that was really unlike anything else I had learned in computer science, and I constantly found myself getting deep into the weeds and loosing sight of the first-principles. 

Until I unstand the links that an idea has to fundamentals, I don't feel like I truly understand it. Reading RTIOW, put me back in contact with the problem of aliasing and with out the tools of graphics apis to solve it. I realized I was lacking knowldge of the link between the problem of aliasing and the fundamentals. 

But what are the fundamentals underlying the problem of aliasing? That would be the field of digital signal processing. 

Computer graphics is really a problem of digital signal processing. The fundamental question is: how do we represent continuous 3 dimensional data, as discrete 2D data? 

Before I go on, I want to say that I'm introducing a huge topic here that will assume some knowledge from the reader. I'm in no place to teach much of that knowledge, nor is that what this post is about. Instead I want to provide an account of my journey through this information, explain some of my newly gained intuition on the subject, and provide resources for others interested in diving deep into the details. 

Raytracing doesn't require that you dig this deep so I'm classifying this section as a tangent. All you really need to know to continue with RTIOW is that alias is a problem, and there are several solutions to solving the problem and pick one to solve it in the context of your applicaiton.

## 2.2 Digital Signal Processing

> "Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations. The digital signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency." - [wiki](https://en.wikipedia.org/wiki/Digital_signal_processing)

In computer graphics, pixels are samples. To be honest, thinking of pixels this way was brand new to me when I first heard it. 

**A pixel is a sample point**

It's not a square, which is my natural interpretation [A pixel is not a little square](http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf). The reason it's intuitive to interpret a pixel as a square in computer graphics has to do with the reconstruction filter (a box filter) used in CG, but not because of some fundamental quality of a pixel. In fact, there are many different kinds reconstruction filters with differing geometric interpretations. So when looking at the math, a pixel is just a sample point.

The basic goal of a reconstruction filter is to smooth the output of a analogue-to-digital converter [reconstruction filter](https://www.sciencedirect.com/topics/engineering/reconstruction-filter). So in the context of raytracing, there are functions in the scene that define the continous surfaces of objects, and we sample the scene a points along a 2D surface (the viewport). Then a box reconstruction filter is used to fill the color of the space between pixel samples.

So why are pixels sample points? The process of converting continuous data into a form that can be represented by a computer involves two steps [image processing book](https://sisu.ut.ee/imageprocessing/book/2):

1. Sampling 
2. Quantization

### 2.2.1 Sampling

### 2.2.2 Quantization


---

I found myself wanting to learn more about the fundamental origin of the issue, and I was delighted to fing that 

I first learned about aliasing pretty early on in my graphics journey. I'd imagine it's the same for most people, as "jaggies" are visible the moment you draw anything that isn't a straight line. I learned that it's a side effect of using pixels to generate images, and it could mostly be handled with some OpenGL setting (TO DO: Look into this, I don't remember how I solved it before, blend?). When I got to the anti aliasing section in RTIOW, I realized I hadn't given much thought to the details of the phenomenon. So, I started doing more research and fell into a mildly deep rabbit hole and gain some really valuable insight into how to think about computer graphics in a fundamental way, and a better understanding of digital signal processing which, as an aspiring Computer Scientist, is something I should be spending more time on. 

There is a really great blog post describing in detail, why aliasing occurs in computer graphics. Check it out [here](https://apoorvaj.io/aliasing-in-computer-graphics/). I'm definitely not going to try and rehash the details here. Instead, I'll explain some of the intuition I gained from reading it.

The first thing I learned is that Aliasing is related to the larger field of signal processing. 

Raytracing can be thought of as sampling a continuous space at descrete intervals. The samples are taken at pixel centers, so the sampling period is the distance between pixel centers{{ page.aliasingpost }}, which is just the size of the pixel.

A pixel is not a square, it is a point sample: [A pixel is not a little square](http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf).

"An image is a rectilinear array of point samples (pixels). The marvelous Sampling Theorem tells us that we can reconstruct a continuous entity from such a discrete entity using an appropriate reconstruction filter 3"

"If the Nyquist rate of the output of this function is greater than our pixel frequency, then aliasing will occur."{{ page.aliasingpost }}

To me, growing as a Computer Scientist means filling gaps of knowledge when I'm faced with one. When I ask myself, "why does aliasing occur," I realize there's a gap. So I spent some time filling the gap with some signal processing information.

Digital image processing is the process of converting continous data, into a form that can be represented by a computer. This is done in two steps: 
1. Sampling
2. Quantization

"The sampling rate determines the spatial resolution of the digitized image, while the quantization level determines the number of grey levels in the digitized image" [image processing book](https://sisu.ut.ee/imageprocessing/book/2)


https://courses.engr.illinois.edu/ece110/sp2021/content/courseNotes/files/?samplingAndQuantization



# . References

<a id="RTIOW">[1]</a>
[RTIOW](https://raytracing.github.io/books/RayTracingInOneWeekend.html)
{: style="font-size: 90%; text-align: left; margin: 0px;"}

<a id="aliasing-in-computer-graphics">[2]</a>
[Aliasing in computer graphics](https://apoorvaj.io/aliasing-in-computer-graphics/)
{: style="font-size: 90%; text-align: left; margin: 0px;"}