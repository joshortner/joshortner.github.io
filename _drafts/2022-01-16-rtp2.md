---
layout: post
title: Aliasing
subtitle: Ray Tracing Journey - Pt2
type: blog
permalink: raytracing-part-two
usemathjax: true

aliasingpost: "[[2]](#aliasing-in-computer-graphics)"
---

* TOC
{:toc}

# 1. Introduction

I'll keep this intro short and sweet. 

I'm picking up where I left off in the [last](https://joshortner.github.io/raytracing-part-one) raytracing post: section 7, [antialiasing](https://raytracing.github.io/books/RayTracingInOneWeekend.html#antialiasing).

# 2. Aliasing 

## 2.1 Tangent Warning

I first encountered aliasing early on in my graphics jouney, as I imagine most do. Drawing anything other than a perfectly vertical or horizontal line often results in a visual artifact known coloquially as "jaggies." 

The image below is a zoomed in version of the final output of the [last](https://joshortner.github.io/raytracing-part-one) ray tracing post. You can see clearly the aliasing effect at the edge of the sphere.

<img src="{{site.url}}/public/media/rt/rtp2/alias-example.jpg" alt="drawing" width="60%" style="margin: 0 auto"/>

I'm going to take a deep dive into aliasing in this post.

Why? Because, I'm curious. I realized when working through RTIOW that I didn't understand why it occurs. I knew about it's visual effect, and I knew a few common techniques for dealing with it, mostly by flipping a switch in OpenGL, but I'd never taken the time to explore the fundamentals surrounding it. 

Usually when I'm made aware of a gaping hole in my understanding of something, I start to loose sleep. There's this killer urge I have that pokes at me until I figure it out. So in the name of a good night's rest, let's dig into the fundamentals underlying aliasing in computer graphics.

## 2.2 Disclaimer

I am by no means in expert in this topic. I hope to simply share some of the intuition I gained in my research and document my learning process. If you're interested in learning for yourself, check out the sources I've linked. They're awesome; very detailed, and mathematically rigorous.

## 2.3 The Starting Point

So where can we find the fundamentals that give rise to aliasing? 

Enter, Digital Signal Processing (DSP). 

Computer graphics is really a sub-problem of DSP. There are two primary questions that this field seeks to answer:

1. How can we represent continuous data discretely? 
2. What can we do with that data after it's been converted it to a digital form?

## 2.4 What is Digital Signal Processing?

> "It is the mathematics, the algorithms, and the techniques used to manipulate ... signals after they have been converted into a digital form" - [DSP Chapter 1](https://www.dspguide.com/ch1/1.htm).

DSP is an area of computer science dedicated to developing methods to analyze *signals*. 

What's a signal? So many things... For the most part, it refers to data generated by the real world. Think, "light, sound, seismic vibrations". DSP provides methods for analyzing these signals in a wide variety of contexts: from space to medical to commercial. But, don't worry, we don't need to understand the entire field of DSP to gain insight into why aliasing occurs in computer graphics. In fact, we need only look at one particular step in the DSP pipeline; it just so happens to be probably the most important step in the entire process: Analog-to-Digital Conversion. 

*Signals* (not always, but mostly always) are continuous in nature: "voltage that varies over time; a chemical reaction rate that depends on temperature" - [DSP Chapter 3](http://www.dspguide.com/ch3.htm). Before a computer can do any kind of reasoning about a signal, it has to be converted to a form that it can understand. In practice this is often done with specialized hardware. Digging into just a bit of the mathematics involved in this process can give us the answers we're looking for as well as a deeper understanding of the graphics pipeline.

### Analog-to-Digital Conversion

There are two main steps involved in converting an analog signal to a digital one: *sampling* and *quantization*. These processes **remove** information from the original source, so the name of the game is understanding what information has to be retained and what information can be lost.

#### Sampling

Sampling is the process of obtaining an instantaneous value of an input signal at periodic intervals - [DSP, Chapter 3](http://www.dspguide.com/ch3.htm). It converts the independent variable of a signal from continous to discrete. And this is important so I'll repeat it: ***Sampling converts the independent variable of a signal from continuous to discrete.***

Take a simple example: a sine wave. The formula of the particular wave below is: $$y = 2\sin{(2x)}$$

<img src="{{site.url}}/public/media/rt/rtp2/simple-sine.png" alt="drawing" width="50%" style="margin: 0 auto"/>

We'll say the independent variable $$x$$ represents some unit of time, and the dependent variable $$y$$ represents some measured value. The units for $$x$$ and $$y$$ could be anything, i.e. amplitude for $$y$$, or time in seconds for $$x$$. We can keep the units abstract and still understand the idea though.

If we sample the signal at every $$\frac{1}{4} \mathrm{time unit}$$, we get the following:

<img src="{{site.url}}/public/media/rt/rtp2/sampled-sine.png" alt="drawing" width="50%" style="margin: 0 auto"/>

The independent time variable has been converted to discrete (green) points. These points along the wave are our new sampled dataset. All of the values on the wave between points are lost. 

There's an actual circuit that performs this operation called a Sample and Hold Circuit (S/H) - [S/H Wiki](https://en.wikipedia.org/wiki/Sample_and_hold).

The output of this process becomes the input to the quantization process. 

#### Quantization

So we've descritized the independent variable, but the dependent variable is still continuous. It can take on values potentially more precise than a computer can represent. If we had an infinite number of bits to work with than there'd probably be no need for quantization (or any of this for that matter), but in practice we are always restricted by the capabilities of our hardware. We have to decide on a method to map the continuous dependent variable to a valid integer or float - [Aliasing in Computer Graphics](https://apoorvaj.io/aliasing-in-computer-graphics/). This is *quantization*.

Quantizing converts a continuous dependent variable into a discrete one. <br>

***Quantizing converts a continuous dependent variable into a discrete one.***

**SHOW GRAPH HERE**

### Proper Sampling

Before moving forward, I'll warn that I'm going to be even more *hand-waving* in this section than I already have been. There is a lot of formal mathematics that I'm skipping over. Again, check out the sources if you're interested.

Despite the fact that both processes *remove* information from the original signal, in some cases it's possible to perfectly reconstruct the original analog signal from it's samples. When this is possble, it's referred to as ***proper sampling***. "The key information has been captured, and the process can be reversed" - [DSP, Chapter 3](http://www.dspguide.com/ch3.htm).

The general idea laid forth in the mathematics is that when sampled properly, there is exactly one signal who's frequency is represented by a set of samples, and so the process can be reverse to reconstruct the original signal perfectly.

The visual examples [here](http://www.dspguide.com/ch3.htm) are really great for understanding this. I'll recreate my own version below.

Take, for example, a straight line. It has a frequency of zero. And it's sampled at every $$\frac{1}{4} \mathrm{time unit}$$, the blue points. In this case, it's clear that the original analog signal can be perfectly reconstructed by connecting the samples with straight line segments.

<img src="{{site.url}}/public/media/rt/rtp2/proper-sampling.png" alt="drawing" width="50%" style="margin: 0 auto"/>

Now, let's increase the frequency of the signal, but retain the same samples. Using the same reconstruction method, straight line segments, will *not* result in the original signal. An informal way to think about it is that there are "things" happening (or there is frequency), between samples. That information is completely lost, and we have no way of knowing that it was ever there. This signal is *improperly sampled*. In fact, you could say that the signal, when sampled at this rate, assumes a frequency that's not it's own - [DSP, Chapter 3](http://www.dspguide.com/ch3.htm). It assumes the frequency of a straight line, when it isn't. It's true identity is hidden. It has an **alias**.

<img src="{{site.url}}/public/media/rt/rtp2/improper-sampling.png" alt="drawing" width="50%" style="margin: 0 auto"/>

Wow... There is is. We made it to the term **alias**. And, the logic above describes how we get to something called the Sampling Theorem. 

> "The sampling theorem indicates that a continuous signal can be properly sampled, only if it does not contain frequency components above one-half of the sampling rate" - [DSP, Chapter 3](http://www.dspguide.com/ch3.htm).

There's a lot more involved in formulating this idea. Hopefully this is enough to start connecting some dots.

### Back to Graphics

Okay, how the heck does all of this tie into computer graphics exactly? Well, it turns out, a pixel, the basic building block of CG, "is not a little square" - [A Pixel Is Not A Little Square](http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf). A pixel is nothing more than a *point* sample.

**example of point grid**

What's actually happening when we reconstruct the data representing a scene is first we are sampling the viewport for the color at a particular point thats been projected onto it from the scene. Second the image is reconstructed for our viewing, by filling the space between pixels using a box reconstruction filter, coloring the display unit (the screen "pixel") of the screen the color of the point sample - [A Pixel Is Not A Little Square](http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf).

A signal in the context of ray tracing is a function that defines the surface of an object in 3D space. The sphere equation discussed in the [last](https://joshortner.github.io/raytracing-part-one) post.

The equation of a sphere centered around $$(Cx, Cy, Cz)$$: 

$$(x - Cx)^2 + (y - Cy)^2 + (z - Cz)^2 - r^2 = 0$$
{: style="text-align: center;" }

To keep things simple, you can think of the signal as being like a step function. At a particular point in space, there either is, or there isn't a surface. 


---


- What are we sampling? The scene, more specifically. The signals in a scene are the objects. So far we've only looked at spheres, so it the spshere equations defined in the last post. Step function [ALIASING POST], the point sample either intersects with the object or it doesn't.


<img src="{{site.url}}/public/media/rt/rtp2/alias-example.jpg" alt="drawing" width="45%" style="margin: 0 auto; float: left; margin-left: 5%;"/>
<img src="{{site.url}}/public/media/rt/rtp2/300-sample-antialiasing.jpg" alt="drawing" width="45%" style="margin: 0 auto"/>

# End

It's interesting what you can learn when you take a deep dive into one topic. I started wanting to learn a bit about the causes of aliasing, I came away with a better understanding of Digital Signal processing, Fourier analysis, and the sampling theorem as well as an entirely new understanding of what a pixel is.

---
- https://www.cs.princeton.edu/courses/archive/fall00/cs426/papers/hanrahan95.pdf

The domain and range of the sample space is the viewport, which is defined by the parameters of the simulated camera. Defining the viewport, and sampling it are two separate processes. So we can look at one without the other. This post is about sampling so we'll assume a viewport has been defined.


In the context of computer graphics, we are interested in image processing, and it turns out that images are special in their characteristics compared to many other signals. 

1. Images are a measure of a parameter over space, not time like most signals 
2. They contain a huge amount of information:
    - To store one second of television video requires 10 megabytes while a similar length voice signal can be store with a thousand times less memory. 
3. The final judge of quality is subjective
[DSP, Ch1: Image Processing](http://www.dspguide.com/ch1/5.htm)

## what is sampling

## what is quantization

## aliasing

- https://technobyte.org/whats-aliasing-dsp-how-to-prevent-it/

## the fourier series

## the sampling therom

## 2.2 Digital Signal Processing

> "Digital signal processing (DSP) is the use of digital processing, such as by computers or more specialized digital signal processors, to perform a wide variety of signal processing operations. The digital signals processed in this manner are a sequence of numbers that represent samples of a continuous variable in a domain such as time, space, or frequency." - [wiki](https://en.wikipedia.org/wiki/Digital_signal_processing)

One of the most fundamental underlying questions asked by computer graphics is: how do we convert the continuous 3D data of a scene into a discrete 2D form. 

In fact, there's an entire field dedicated to formulating methods of converting continous data into discrete data, while preserving as much information as possible. 

[American Scientist](https://www.americanscientist.org/article/a-pixel-is-not-a-little-square)

The second sentence in the above quote is the most important. In computer graphics, the continuous data is a model, in what ever form that takes. In the case of raytracing a sphere it's the ray-sphere intersection formula described in RTIOW. In the case of the traditional rasterization pipeline, it's a triangle mesh. The samples are the pixels (and this was very new to me). 

In computer graphics, pixels are samples. To be honest, thinking of pixels this way was brand new to me when I first heard it. 

**A pixel is a sample point**

It's not a square, which is my natural interpretation [A pixel is not a little square](http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf). The reason it's intuitive to interpret a pixel as a square in computer graphics has to do with the reconstruction filter (a box filter) used in CG, but not because of some fundamental quality of a pixel. In fact, there are many different kinds reconstruction filters with differing geometric interpretations. So when looking at the math, a pixel is just a sample point.

The basic goal of a reconstruction filter is to smooth the output of a analogue-to-digital converter [reconstruction filter](https://www.sciencedirect.com/topics/engineering/reconstruction-filter). So in the context of raytracing, there are functions in the scene that define the continous surfaces of objects, and we sample the scene a points along a 2D surface (the viewport). Then a box reconstruction filter is used to fill the color of the space between pixel samples.

So why are pixels sample points? The process of converting continuous data into a form that can be represented by a computer involves two steps [image processing book](https://sisu.ut.ee/imageprocessing/book/2):

1. Sampling 
2. Quantization

### 2.2.1 Sampling

### 2.2.2 Quantization


---

I found myself wanting to learn more about the fundamental origin of the issue, and I was delighted to fing that 

I first learned about aliasing pretty early on in my graphics journey. I'd imagine it's the same for most people, as "jaggies" are visible the moment you draw anything that isn't a straight line. I learned that it's a side effect of using pixels to generate images, and it could mostly be handled with some OpenGL setting (TO DO: Look into this, I don't remember how I solved it before, blend?). When I got to the anti aliasing section in RTIOW, I realized I hadn't given much thought to the details of the phenomenon. So, I started doing more research and fell into a mildly deep rabbit hole and gain some really valuable insight into how to think about computer graphics in a fundamental way, and a better understanding of digital signal processing which, as an aspiring Computer Scientist, is something I should be spending more time on. 

There is a really great blog post describing in detail, why aliasing occurs in computer graphics. Check it out [here](https://apoorvaj.io/aliasing-in-computer-graphics/). I'm definitely not going to try and rehash the details here. Instead, I'll explain some of the intuition I gained from reading it.

The first thing I learned is that Aliasing is related to the larger field of signal processing. 

Raytracing can be thought of as sampling a continuous space at descrete intervals. The samples are taken at pixel centers, so the sampling period is the distance between pixel centers{{ page.aliasingpost }}, which is just the size of the pixel.

A pixel is not a square, it is a point sample: [A pixel is not a little square](http://alvyray.com/Memos/CG/Microsoft/6_pixel.pdf).

"An image is a rectilinear array of point samples (pixels). The marvelous Sampling Theorem tells us that we can reconstruct a continuous entity from such a discrete entity using an appropriate reconstruction filter 3"

"If the Nyquist rate of the output of this function is greater than our pixel frequency, then aliasing will occur."{{ page.aliasingpost }}

To me, growing as a Computer Scientist means filling gaps of knowledge when I'm faced with one. When I ask myself, "why does aliasing occur," I realize there's a gap. So I spent some time filling the gap with some signal processing information.

Digital image processing is the process of converting continous data, into a form that can be represented by a computer. This is done in two steps: 
1. Sampling
2. Quantization

"The sampling rate determines the spatial resolution of the digitized image, while the quantization level determines the number of grey levels in the digitized image" [image processing book](https://sisu.ut.ee/imageprocessing/book/2)


https://courses.engr.illinois.edu/ece110/sp2021/content/courseNotes/files/?samplingAndQuantization



# . References

<a id="RTIOW">[1]</a>
[RTIOW](https://raytracing.github.io/books/RayTracingInOneWeekend.html)
{: style="font-size: 90%; text-align: left; margin: 0px;"}

<a id="aliasing-in-computer-graphics">[2]</a>
[Aliasing in computer graphics](https://apoorvaj.io/aliasing-in-computer-graphics/)
{: style="font-size: 90%; text-align: left; margin: 0px;"}